\chapter{Literature Review and Related Work}
\label{chap:relatedworks}

\section{Competitor Analysis}
\label{section:competitor-analysis}

\begin{table}[htbp!]
    \begin{adjustwidth}{-.85in}{-.85in}
        \noindent
        \centering
        \small\begin{tabularx}{1.3\textwidth}{|X|>{\columncolor{green!20}}X|X|X|X|}
            \hline & \textbf{\usevar{\srsTitle}} & \textbf{Hikvision} & \textbf{YOLORe-IDNet} & \textbf{JARVIS-MoCap} \\\hline
            \textbf{Primary Focus} & Campus-optimized tracking with persistent identity & General surveillance with limited identity tracking & Tracking without historical context & Research-focused motion capture \\\hline
            \textbf{Core Technology} & Multi-model fusion with adaptive learning & Proprietary algorithms with fixed parameters & Single detection model with re-ID & Research-oriented pose estimation \\\hline
            \textbf{Identity Preservation} & Continuous tracking across blind spots & Limited to overlapping camera views & Struggles with extended disappearances & Requires continuous visibility \\\hline
            \textbf{Environmental Adaptation} & Self-calibrating for any lighting/weather & Pre-configured environmental settings & Limited adaptation capabilities & Controlled environment only \\\hline
            \textbf{Spatial Integration} & 3D mapping with interactive UI & 2D mapping with fixed views & Limited spatial representation & Lab-specific spatial modeling \\\hline
            \textbf{Integration API} & Open REST API with event streaming & Closed ecosystem with limited exports & No documented API & Research code only \\\hline
            \textbf{Tech Stack} & FastAPI backend, Next.js frontend, Docker/NGINX deployment & Proprietary software stack & Research implementation only & Python libraries without web interface \\\hline
            \textbf{Cross-Platform Support} & Web-based interface accessible from any device & Dedicated monitoring stations & Command-line interface & Desktop application only \\\hline
        \end{tabularx}
    \end{adjustwidth}
    \caption{Competitor Analysis of Intelligent Multi-Camera Person Tracking System}
\end{table}

In order to acknowledge the existing technology with similar functionalities, a competitor analysis is conducted.
There are various systems in the market that can track individuals across multiple cameras, we have selected 3 of which most closely resemble our project:

\begin{itemize}
    \item \textbf{\textit{Hikvision AI Camera Systems}}---a commercial leader in the Thailand AI camera market offering multi-camera tracking solutions primarily for general security applications.
    \item \textbf{\textit{YOLORe-IDNet}}---a research implementation combining YOLO object detection with re-identification networks for real-time tracking without prior knowledge.
    \item \textbf{\textit{JARVIS-MoCap}}---an open-source markerless 3D motion capture system designed for research environments requiring precise tracking.
\end{itemize}
\par
The \usevar{\srsTitle} stands apart from competitors through its unique combination of persistent identity tracking across non-overlapping camera views and blind spots, a capability not found in Hikvision's proprietary hardware-dependent solution or YOLORe-IDNet's research implementation. Unlike JARVIS-MoCap, which requires controlled environments and specialized equipment, our system works with existing camera infrastructure and adapts to varying lighting conditions through self-calibrating algorithms. Our multi-model fusion approach ensures reliable tracking even when subjects disappear from view temporarily, maintaining identity across campus blind spots where other systems lose track. The system's interactive 3D mapping provides security personnel with comprehensive spatial awareness that surpasses the limited 2D representations of competitors, making it uniquely suited for complex campus environments where maintaining continuous identity is critical for security operations.

\section{Literature Review}
\label{section:literature-review}


The development of multi-camera person tracking systems represents a significant advancement in computer vision and surveillance technology, addressing the fundamental challenge of maintaining consistent identification of individuals as they move through spaces monitored by multiple cameras. This literature review examines the current state of the art in multi-camera tracking, focusing on the three key technical challenges our system addresses: cross-camera identity preservation, environmental adaptation, and spatial mapping.

Zhang et al. \cite{bytetrack} introduced ByteTrack, a simple yet effective association method that tracks by associating nearly all detection boxes rather than only high-confidence ones. This approach significantly reduces missed detections and trajectory fragmentation, achieving state-of-the-art performance on multiple tracking benchmarks. ByteTrack's approach to maintaining object identity despite occlusions and low-confidence detections provides valuable insights for our system's identity preservation mechanisms.

He et al. \cite{fastreid} developed FastReID, a modular and extensible software system for general instance re-identification. Its architecture allows researchers to easily implement and test new ideas without rewriting the codebase, accelerating the transition from research to production. FastReID's approach to person re-identification across different camera views informs our system's cross-camera identity preservation strategy.

For 3D spatial mapping, Bredereke et al. \cite{modular3d} proposed a modular pipeline that calculates 3D trajectories of multiple objects using RGB cameras. Their approach is adaptable to various settings with multiple time-synchronized stationary cameras, demonstrating the feasibility of creating accurate spatial representations from multi-camera inputs. This work provides a foundation for our system's spatial mapping capabilities.

Woo et al. \cite{mtmmc} presented MTMMC, a comprehensive real-world dataset captured by 16 multi-modal cameras across campus and factory environments under varying conditions. This dataset serves as a valuable benchmark for multi-camera tracking systems and highlights the importance of handling diverse environmental conditions, a key consideration in our system design.

Gautam et al. \cite{yoloreidnet} proposed YOLORe-IDNet, an efficient multi-camera system for person tracking that combines correlation filters and IOU constraints with a deep learning model for cross-camera person re-identification. Their system demonstrates robust performance in security applications, particularly in recovering identities after occlusion, which aligns with our system's focus on persistent identity tracking.

The Thailand AI CCTV Market is experiencing significant growth, valued at USD 342.1 million in 2023 and projected to reach USD 1,381.1 million by 2030, growing at a CAGR of 20.2\% from 2024 to 2030 \cite{thailand:market}. This expansion is driven by increasing demand for advanced security solutions and the Thai government's focus on smart city development and traffic management initiatives.

In conclusion, while existing systems have made significant progress in multi-camera tracking, there remains a gap in solutions that effectively integrate persistent identity tracking, environmental adaptation, and interactive spatial mapping for campus applications. Our \usevar{\srsTitle} addresses this gap by combining state-of-the-art computer vision techniques designed for practical deployment in real-world environments.