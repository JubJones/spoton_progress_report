% Define table for personas.
\newcommand{\persona}[4]{%
    \textbf{#1}
    \small\begin{tabular}[t]{|p{.8in} | p{1.5in}|}
        \hline
        \textbf{Preferences} & #2 \\\hline
        \textbf{Pain Points} & #3 \\\hline
        \textbf{Goals} & #4 \\
        \hline
    \end{tabular}
    \vspace{4pt}
}


\chapter{Introduction}
\label{chap:introduction}

\section{Background}
\label{section:background}

In campus and factory settings, keeping track of people across multiple cameras is important for safety, daily operations, and space management. Security teams need to watch for unusual activities, managers need to understand how spaces are used, and emergency teams need to know where people are during incidents. Without good tracking systems, there are blind spots in coverage, making both safety and operations less effective \cite{wangetal:2021}.
When a person walks from the view of one camera to another, keeping track of who they are becomes difficult. Current systems often lose track of people during these transitions, creating gaps in surveillance coverage. This problem is especially noticeable in large campuses with many buildings or factories with complex layouts where many cameras work separately without sharing information about who they're tracking.
The environment makes tracking even harder. Different lighting between indoor and outdoor areas, crowded spaces during busy hours, and objects blocking the view create situations where people are often lost from sight. Also, cameras placed at different heights and angles show very different views of the same person, making it hard to match them across cameras.
The goal of this project is to create a tracking system that can keep track of people consistently across multiple cameras, providing complete coverage in campus and factory environments. By solving the challenge of maintaining identity across cameras, our solution aims to improve security monitoring, speed up emergency response, and provide useful information for facility management and resource planning.

\section{Problem Statement}
\label{section:problem-statement}

The problem statement for our multi-camera tracking system addresses the fundamental challenge of maintaining consistent identification of individuals as they move through spaces monitored by multiple cameras. In various environments from campuses and factories to public spaces and transportation hubs, the ability to track individuals across camera transitions is critical yet remains largely unsolved. When a person moves from one camera's view to another, current systems frequently lose their identity trail, creating fragmented tracking data that fails during situations requiring continuous monitoring. This tracking discontinuity affects numerous applicationsâ€”from security monitoring and emergency response to space utilization analysis and research on movement patterns. The consequences include critical delays during time-sensitive situations, incomplete data for operational decision-making, and increased workload for monitoring personnel who must manually reconnect identity fragments across camera boundaries.
Technically, this challenge manifests in three interconnected problems. First, the cross-camera identity preservation problem requires maintaining consistent identification as individuals move between non-overlapping camera views, often with significant time gaps and appearance changes due to different viewing angles. Second, the environmental adaptation problem involves reliable detection and tracking despite varying lighting conditions between indoor hallways and outdoor pathways, seasonal changes affecting clothing appearance, and crowded periods creating frequent occlusions. Third, the spatial mapping problem necessitates transforming observations from distributed cameras into a unified coordinate system to enable continuous trajectory tracking across the entire campus or factory layout. Current systems address these problems in isolation rather than as an integrated challenge, resulting in fragmented surveillance coverage that fails during critical monitoring scenarios.

\section{Solution Overview}
\label{section:solution-overview}

The \usevar{\srsTitle} addresses multi-camera person tracking challenges through an integrated computer vision platform with three core technical components:

\subsection{Prominent Features}
\label{subsection:main-features}

\begin{enumerate}[leftmargin=80pt]
    \item \textbf{Multi-View Person Detection:} A detection system that identifies individuals in each camera feed using specialized algorithms optimized for diverse environments. The system processes each video stream independently to locate and track all persons present, handling partial occlusions, varying lighting conditions between indoor and outdoor spaces, and environmental changes affecting appearance.
    
    \item \textbf{Cross-Camera Re-Identification:} A re-identification system that solves the identity preservation problem across camera views through robust feature extraction and matching. When a person exits one camera's field of view and appears in another, potentially minutes later in a different location, the system matches appearance features with previously tracked individuals to maintain consistent identification despite significant spatial and temporal gaps.
    
    \item \textbf{Unified Spatial Mapping:} A mapping system that transforms detections from distributed cameras into a coherent coordinate system. This integration enables continuous trajectory visualization as individuals move through the monitored environment across multiple camera views, providing operators with a comprehensive spatial understanding of movement patterns throughout the facility.
\end{enumerate}

\subsection{Optional Features}
\label{subsection:optional-features}

\begin{enumerate}[leftmargin=80pt]
    \item \textbf{LLM-Powered Person Selection:} A natural language interface that allows users to identify individuals based on descriptive prompts (e.g., "Find the person wearing a black jacket and jeans who passed through the main entrance at 2:30 PM" or "Locate the individual with a red backpack near the cafeteria"), with an interactive confirmation step where users select the correct person from highlighted candidates.
    \item \textbf{Multi-Person Tracking:} Capability to simultaneously maintain identity and location data for multiple individuals across the camera network, preserving each person's unique identity despite occlusions, varying viewing angles, or extended periods where individuals are not visible in any camera.
    \item \textbf{Movement Pattern Analysis:} AI-powered analysis to identify typical movement patterns and provide insights for space utilization, traffic management, and anomaly detection in pedestrian flows across the monitored environment.
    \item \textbf{Environmental Analytics Dashboard:} Real-time metrics including occupancy density maps, path trajectory analysis, and movement pattern heatmaps tailored for facility management, safety monitoring, and resource optimization.
\end{enumerate}

\subsection{Stretch Goals}
\label{subsection:stretch-goals}

\begin{enumerate}[leftmargin=80pt]
    \item \textbf{Voice Command Integration:} Allow personnel to interact with the system using natural voice commands (e.g., "Track the person in the blue jacket heading toward Building B") for hands-free operation during critical situations.
    \item \textbf{Anomaly Detection:} Implement AI-powered anomaly detection to automatically identify unusual behavior patterns (such as suspicious movements, crowd formations, or potential security incidents) across the monitored environment.
    \item \textbf{Privacy-Preserving Tracking:} Implement anonymization techniques that maintain tracking capabilities while protecting individual privacy through face blurring or feature abstraction in accordance with surveillance regulations and privacy laws.
    \item \textbf{Automatic Environment Mapping:} System that creates spatial representations based on observed movement patterns, automatically identifying walkways, intersections, and common routes without requiring manual mapping of the environment.
\end{enumerate}

\section{Target User}
\label{section:target-user}

The \usevar{\srsTitle} enables security, facility management, and emergency response professionals to maintain consistent identification of individuals across multiple camera views in campus and factory environments, enhancing safety, optimizing resources, and improving response times.
The primary users are professionals responsible for monitoring complex environments with distributed camera networks.

\begin{table}[p]
    \centering
    \noindent\begin{tabular}{| p{2.65in} | p{2.65in} |}
        \hline & \\[-10pt]
        \persona{Campus Security Officer}
        {Track subjects across buildings, integrate security protocols.}
        {Loses track between cameras, wastes time searching feeds during incidents.}
        {Locate persons quickly, maintain tracking throughout facility, coordinate based on location.} &
        \persona{Facility Operations Manager}
        {Monitor occupancy, analyze usage, optimize resources.}
        {Cannot analyze movement patterns for resource allocation or identify bottlenecks.}
        {Optimize space use, identify congestion, improve efficiency with data.} \\[10pt]
        \hline & \\[-10pt]
        \persona{Emergency Response Coordinator}
        {Track evacuations, monitor crowding, coordinate resources.}
        {Limited situation awareness, difficulty tracking individuals needing assistance.}
        {Monitor safety issues, coordinate resources, maintain multi-zone awareness.} &
        \persona{Research Analyst}
        {Analyze movement patterns, behavioral insights, space usage.}
        {Lacks integrated view of navigation patterns and space effects.}
        {Understand space usage, identify underused areas, recommend data-driven improvements.} \\[10pt]
        \hline
    \end{tabular}
    \caption{Personas from User Analysis for Intelligent Multi-Camera Person Tracking System}
\end{table}

\newpage

\section{Benefit}
\label{section:benefit}
The \usevar{\srsTitle} delivers benefits directly addressing the three key challenges in multi-camera tracking. The multi-view person detection with environmental adaptation ensures reliable tracking despite lighting changes, occlusions, and perspective differences.
The cross-camera re-identification solves the identity preservation problem by maintaining continuous tracking between cameras, eliminating fragmentation when individuals move through non-overlapping camera networks.
The unified spatial mapping creates a comprehensive environmental understanding by integrating all camera feeds into a single coordinate system, allowing operators to visualize movement patterns spanning multiple buildings and zones.
These capabilities translate to 70\% reduced manual tracking workload, faster incident response times, more effective resource allocation, and comprehensive situational awareness across the entire monitored environment.

\section{Timeline}
\label{section:timeline}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{jubjones/timeline.png}
    \caption{Timeline for Intelligent Multi-Camera Person Tracking System Project}
    \label{fig:timeline}
\end{figure}

As shown in figure \ref{fig:timeline}, it represents the timeline of the project.
The project began with system architecture design in January 2025, followed by the development of core detection
and tracking modules optimized for urban environments in February 2025. The re-identification and LLM integration components are scheduled for
completion by mid-March 2025.
System integration testing with actual urban camera networks will commence in late March 2025, with user acceptance testing planned for early April 2025.
The final deployment and handover are scheduled for completion by the end of April 2025, with ongoing support
and maintenance to follow.

\section{Terminology}
\label{section:terminology}

\begin{itemize}[leftmargin=40pt]
    \item \textbf{\textit{Object Detection}}---a computer vision technique that identifies and locates objects within digital images or video frames, serving as the foundation for tracking individuals in each camera view.
    \item \textbf{\textit{Re-Identification (Re-ID)}}---the process of matching individuals across different camera views by comparing appearance features, enabling consistent identity preservation as people move between cameras.
    \item \textbf{\textit{Multi-Target Multi-Camera Tracking (MTMCT)}}---the task of tracking multiple individuals across a network of cameras with non-overlapping fields of view, maintaining identity consistency despite spatial and temporal gaps.
    \item \textbf{\textit{Feature Extraction}}---the process of identifying distinctive visual characteristics from a person's image that remain consistent despite environmental variations, critical for successful re-identification.
    \item \textbf{\textit{Spatial Mapping}}---a technique that converts observations from multiple camera views into a unified coordinate system, enabling continuous trajectory visualization across the entire monitored environment.
    \item \textbf{\textit{Occlusion Handling}}---methods to maintain tracking when individuals are partially or temporarily hidden by objects, structures, or other people in the camera view.
\end{itemize}