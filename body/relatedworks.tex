\chapter{Literature Review and Related Work}
\label{chap:relatedworks}

\section{Competitor Analysis}
\label{section:competitor-analysis}

\begin{table}[htbp!]
   \begin{adjustwidth}{-.85in}{-.85in}
       \noindent
       \centering
       \small\begin{tabularx}{1.3\textwidth}{|X|>{\columncolor{green!20}}X|X|X|X|}
           \hline & \textbf{\usevar{\srsTitle}} & \textbf{Hikvision} & \textbf{YOLORe-IDNet} & \textbf{JARVIS-MoCap} \\\hline
           \textbf{Primary Focus} & Campus tracking with persistent identity & Single-camera surveillance with minimal cross-camera capability & Real-time detection without integrated systems & Research motion capture in controlled settings \\\hline
           \textbf{Core Technology} & Multi-model fusion with spatial mapping & Proprietary algorithms optimized for single views & YOLO detection with separate Re-ID network & Markerless pose estimation with synced cameras \\\hline
           \textbf{Multi-Camera Detection} & Independent detection robust to occlusions & Strong within-view detection, poor across views & No multi-camera management system & Requires calibrated camera arrays \\\hline
           \textbf{Tracking and Re-ID} & Identity across non-overlapping views & Excellent within single views, fails across views & Matches appearance without trajectories & Tracks pose, not identity \\\hline
           \textbf{Spatial Representation} & Unified coordinate system visualization & Limited to individual camera views & No spatial mapping functionality & Limited to pre-calibrated environments \\\hline
           \textbf{System Accessibility} & Web interface with easy deployment & Requires dedicated hardware & Command-line interface for experts & Research software with complex setup \\\hline
           \textbf{Cross-Platform Support} & Any device with browser access & Specific hardware and OS requirements & Platform-dependent implementation & Desktop with specific dependencies \\\hline
       \end{tabularx}
   \end{adjustwidth}
   \caption{Competitor Analysis of Intelligent Multi-Camera Person Tracking System}
\end{table}

In order to acknowledge the existing technology with similar functionalities, a competitor analysis is conducted.
There are various systems in the market that can track individuals across multiple cameras, we have selected 3 of which most closely resemble our project:

\begin{itemize}
   \item \textbf{\textit{Hikvision AI Camera Systems}}---a commercial leader in the Thailand AI camera market offering excellent single-camera tracking but limited cross-camera capabilities.
   \item \textbf{\textit{YOLORe-IDNet}}---a research implementation combining YOLO object detection with re-identification networks for real-time tracking without prior knowledge.
   \item \textbf{\textit{JARVIS-MoCap}}---an open-source markerless 3D motion capture system designed for research environments requiring precise tracking.
\end{itemize}
\par
The \usevar{\srsTitle} stands apart from competitors through its unique combination of persistent identity tracking across non-overlapping camera views and blind spots, a capability not found in Hikvision's proprietary hardware-dependent solution which excels at single-camera tracking but fails across non-overlapping views with time gaps. Unlike YOLORe-IDNet's research implementation which lacks continuous identity maintenance, our system preserves identity even when subjects disappear temporarily. JARVIS-MoCap requires controlled environments and specialized equipment, while our system works with existing camera infrastructure and adapts to varying lighting conditions through self-calibrating algorithms. Our multi-model fusion approach ensures reliable tracking even in campus blind spots where other systems lose track. The system's interactive 3D mapping provides security personnel with comprehensive spatial awareness that surpasses the limited single-view representations of competitors, making it uniquely suited for complex campus environments where maintaining continuous identity is critical for security operations.

\section{Literature Review}
\label{section:literature-review}

The development of multi-camera person tracking systems represents a significant advancement in computer vision and surveillance technology, addressing the fundamental challenge of maintaining consistent identification of individuals as they move through spaces monitored by multiple cameras. This literature review examines the current state of the art in multi-camera tracking, focusing on the three key technical challenges our system addresses: cross-camera identity preservation, environmental adaptation, and spatial mapping.

Zhang et al. \cite{bytetrack} introduced ByteTrack, a simple yet effective association method that tracks by associating nearly all detection boxes rather than only high-confidence ones. This approach significantly reduces missed detections and trajectory fragmentation, achieving state-of-the-art performance on multiple tracking benchmarks. ByteTrack's approach to maintaining object identity despite occlusions and low-confidence detections provides valuable insights for our system's identity preservation mechanisms.

He et al. \cite{fastreid} developed FastReID, a modular and extensible software system for general instance re-identification. Its architecture allows researchers to easily implement and test new ideas without rewriting the codebase, accelerating the transition from research to production. FastReID's approach to person re-identification across different camera views informs our system's cross-camera identity preservation strategy.

For 3D spatial mapping, Bredereke et al. \cite{modular3d} proposed a modular pipeline that calculates 3D trajectories of multiple objects using RGB cameras. Their approach is adaptable to various settings with multiple time-synchronized stationary cameras, demonstrating the feasibility of creating accurate spatial representations from multi-camera inputs. This work provides a foundation for our system's spatial mapping capabilities.

Woo et al. \cite{mtmmc} presented MTMMC, a comprehensive real-world dataset captured by 16 multi-modal cameras across campus and factory environments under varying conditions. This dataset serves as a valuable benchmark for multi-camera tracking systems and highlights the importance of handling diverse environmental conditions, a key consideration in our system design.

Gautam et al. \cite{yoloreidnet} proposed YOLORe-IDNet, an efficient multi-camera system for person tracking that combines correlation filters and IOU constraints with a deep learning model for cross-camera person re-identification. Their system demonstrates robust performance in security applications, particularly in recovering identities after occlusion, which aligns with our system's focus on persistent identity tracking.

The Thailand AI CCTV Market is experiencing significant growth, valued at USD 342.1 million in 2023 and projected to reach USD 1,381.1 million by 2030, growing at a CAGR of 20.2\% from 2024 to 2030 \cite{thailand:market}. This expansion is driven by increasing demand for advanced security solutions and the Thai government's focus on smart city development and traffic management initiatives.

In conclusion, while existing systems have made significant progress in multi-camera tracking, there remains a gap in solutions that effectively integrate persistent identity tracking, environmental adaptation, and interactive spatial mapping for campus applications. Our \usevar{\srsTitle} addresses this gap by combining state-of-the-art computer vision techniques designed for practical deployment in real-world environments.